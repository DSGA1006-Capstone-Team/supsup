[{'config': 'experiments/SupsupSeed/splitcifar100/configs/rn18-supsup_5.yaml', 'name': 'id=supsup~seed=0~sparsity=1', 'sparsity': 1, 'seed': 0, 'log-dir': 'runs/SupsupSeed/rn18-supsup_num_masks_5', 'epochs': 250, 'data': './data'}, {'config': 'experiments/SupsupSeed/splitcifar100/configs/rn18-supsup_5.yaml', 'name': 'id=supsup~seed=0~sparsity=2', 'sparsity': 2, 'seed': 0, 'log-dir': 'runs/SupsupSeed/rn18-supsup_num_masks_5', 'epochs': 250, 'data': './data'}, {'config': 'experiments/SupsupSeed/splitcifar100/configs/rn18-supsup_5.yaml', 'name': 'id=supsup~seed=0~sparsity=4', 'sparsity': 4, 'seed': 0, 'log-dir': 'runs/SupsupSeed/rn18-supsup_num_masks_5', 'epochs': 250, 'data': './data'}, {'config': 'experiments/SupsupSeed/splitcifar100/configs/rn18-supsup_5.yaml', 'name': 'id=supsup~seed=0~sparsity=8', 'sparsity': 8, 'seed': 0, 'log-dir': 'runs/SupsupSeed/rn18-supsup_num_masks_5', 'epochs': 250, 'data': './data'}, {'config': 'experiments/SupsupSeed/splitcifar100/configs/rn18-supsup_5.yaml', 'name': 'id=supsup~seed=0~sparsity=16', 'sparsity': 16, 'seed': 0, 'log-dir': 'runs/SupsupSeed/rn18-supsup_num_masks_5', 'epochs': 250, 'data': './data'}, {'config': 'experiments/SupsupSeed/splitcifar100/configs/rn18-supsup_5.yaml', 'name': 'id=supsup~seed=0~sparsity=32', 'sparsity': 32, 'seed': 0, 'log-dir': 'runs/SupsupSeed/rn18-supsup_num_masks_5', 'epochs': 250, 'data': './data'}]
=> Reading YAML config from experiments/SupsupSeed/splitcifar100/configs/rn18-supsup_5.yaml
=> Saving data in runs/SupsupSeed/rn18-supsup_num_masks_5/id=supsup~seed=0~sparsity=1~try=0
Files already downloaded and verified
Files already downloaded and verified
[26 86  2 55 75 93 16 73 54 95 53 92 78 13  7 30 22 24 33  8 43 62  3 71
 45 48  6 99 82 76 60 80 90 68 51 27 18 56 63 74  1 61 42 41  4 15 17 40
 38  5 91 59  0 34 28 50 11 35 23 52 10 31 66 57 79 85 32 84 14 89 19 29
 49 97 98 69 20 94 72 77 25 37 81 46 39 65 58 12 88 70 87 36 21 83  9 96
 67 64 47 44]
[26 86  2 55 75]
[93 16 73 54 95]
[53 92 78 13  7]
[30 22 24 33  8]
[43 62  3 71 45]
Set sparsity of conv1 to 0.04259259259259259
Set sparsity of layer1.0.conv1 to 0.011111111111111112
Set sparsity of layer1.0.conv2 to 0.011111111111111112
Set sparsity of layer1.1.conv1 to 0.011111111111111112
Set sparsity of layer1.1.conv2 to 0.011111111111111112
Set sparsity of layer2.0.conv1 to 0.008333333333333333
Set sparsity of layer2.0.conv2 to 0.005555555555555556
Set sparsity of layer2.0.shortcut.0 to 0.075
Set sparsity of layer2.1.conv1 to 0.005555555555555556
Set sparsity of layer2.1.conv2 to 0.005555555555555556
Set sparsity of layer3.0.conv1 to 0.004166666666666667
Set sparsity of layer3.0.conv2 to 0.002777777777777778
Set sparsity of layer3.0.shortcut.0 to 0.0375
Set sparsity of layer3.1.conv1 to 0.002777777777777778
Set sparsity of layer3.1.conv2 to 0.002777777777777778
Set sparsity of layer4.0.conv1 to 0.0020833333333333333
Set sparsity of layer4.0.conv2 to 0.001388888888888889
Set sparsity of layer4.0.shortcut.0 to 0.01875
Set sparsity of layer4.1.conv1 to 0.001388888888888889
Set sparsity of layer4.1.conv2 to 0.001388888888888889
Set sparsity of linear to 0.20625
=> Parallelizing on [0] gpus
=> Using trainer <module 'trainers.default' from '/home/at2507/supsup_team/supsup/trainers/default.py'>
Task RandSplitCIFAR100: 0
Train Epoch: 1 [0/2500 (0%)]	Loss: 1.621132
Train Epoch: 1 [1280/2500 (50%)]	Loss: 1.471176

Test set: Average loss: 1.2920, Accuracy: (0.4620)

Train Epoch: 2 [0/2500 (0%)]	Loss: 1.356100
Train Epoch: 2 [1280/2500 (50%)]	Loss: 1.399404

Test set: Average loss: 1.2476, Accuracy: (0.4960)

Train Epoch: 3 [0/2500 (0%)]	Loss: 1.357259
Train Epoch: 3 [1280/2500 (50%)]	Loss: 1.318779

Test set: Average loss: 1.2080, Accuracy: (0.5180)

Train Epoch: 4 [0/2500 (0%)]	Loss: 1.294610
Train Epoch: 4 [1280/2500 (50%)]	Loss: 1.274727

Test set: Average loss: 1.2214, Accuracy: (0.5080)

Train Epoch: 5 [0/2500 (0%)]	Loss: 1.305308
Train Epoch: 5 [1280/2500 (50%)]	Loss: 1.258319

Test set: Average loss: 1.2489, Accuracy: (0.4620)

Train Epoch: 6 [0/2500 (0%)]	Loss: 1.284700
Train Epoch: 6 [1280/2500 (50%)]	Loss: 1.187598

Test set: Average loss: 1.1853, Accuracy: (0.5460)

Train Epoch: 7 [0/2500 (0%)]	Loss: 1.223891
Train Epoch: 7 [1280/2500 (50%)]	Loss: 1.164341

Test set: Average loss: 1.1586, Accuracy: (0.5540)

Train Epoch: 8 [0/2500 (0%)]	Loss: 1.085425
Train Epoch: 8 [1280/2500 (50%)]	Loss: 1.139027

Test set: Average loss: 1.1030, Accuracy: (0.5840)

Train Epoch: 9 [0/2500 (0%)]	Loss: 1.045908
Train Epoch: 9 [1280/2500 (50%)]	Loss: 1.019437

Test set: Average loss: 1.0730, Accuracy: (0.5780)

Train Epoch: 10 [0/2500 (0%)]	Loss: 0.982574
Train Epoch: 10 [1280/2500 (50%)]	Loss: 1.137644

Test set: Average loss: 1.1198, Accuracy: (0.5720)

Train Epoch: 11 [0/2500 (0%)]	Loss: 1.152528
Train Epoch: 11 [1280/2500 (50%)]	Loss: 1.055207

Test set: Average loss: 1.1576, Accuracy: (0.5380)

Train Epoch: 12 [0/2500 (0%)]	Loss: 1.172414
Train Epoch: 12 [1280/2500 (50%)]	Loss: 1.040011

Test set: Average loss: 1.0749, Accuracy: (0.5960)

Train Epoch: 13 [0/2500 (0%)]	Loss: 1.163464
Train Epoch: 13 [1280/2500 (50%)]	Loss: 1.145309

Test set: Average loss: 1.0460, Accuracy: (0.6020)

Train Epoch: 14 [0/2500 (0%)]	Loss: 1.081951
Train Epoch: 14 [1280/2500 (50%)]	Loss: 0.999060

Test set: Average loss: 1.0329, Accuracy: (0.6040)

Train Epoch: 15 [0/2500 (0%)]	Loss: 0.799654
Train Epoch: 15 [1280/2500 (50%)]	Loss: 1.133186

Test set: Average loss: 1.0674, Accuracy: (0.5920)

Train Epoch: 16 [0/2500 (0%)]	Loss: 1.092762
Train Epoch: 16 [1280/2500 (50%)]	Loss: 1.078082

Test set: Average loss: 0.9806, Accuracy: (0.6400)

